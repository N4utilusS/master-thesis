\documentclass[oneside, a4paper, 12pt]{memoir}

\usepackage[utf8]{inputenc}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[marginparwidth=28mm]{geometry}
\usepackage[pdftex]{graphicx}
\usepackage{tikz}

\usepackage{filecontents}
\usepackage[T1]{fontenc}
\usepackage[UKenglish]{babel}
\usepackage{newpxtext,newpxmath}
\usepackage[babel=true]{csquotes}
\usepackage[round]{natbib}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{comment}
\usepackage{tikz}
\usetikzlibrary{arrows,automata}
\usepackage{ccaption}
\usepackage{url}
\usepackage{flafter}
\usepackage{pgfplots}

% Logos
\newcommand{\ulb}{\includegraphics[scale=1.1]{PageDeGarde_MFE/logo_ULB2.pdf}}
\newcommand{\polytech}{\includegraphics[scale=0.35]{PageDeGarde_MFE/logo_polytech_FR.pdf}}

% Polices
\definecolor{ULBblue}{rgb}{0,0.2196,0.5765}
\newcommand{\fontTitle}{\sffamily \Huge\selectfont \color{ULBblue}}
\newcommand{\fontSubtitle}{\sffamily \LARGE \selectfont \color{ULBblue}}
\newcommand{\fontText}{\sffamily \selectfont}
\newcommand{\fontColor}{\sffamily \selectfont \color{ULBblue}}

% Titre
\newcommand{\titleA}{\fontTitle{Human - Robots Swarms Interaction}} % Titre identique au titre remis au secrétariat
%\newcommand{\titleB}{\fontTitle{Deuxième ligne de titre du mémoire}} % (dans la langue de rédaction a priori)
% Sous-titre
\newcommand{\subtitleA}{\fontSubtitle{An Escorting Robot Swarm that Diverts a Human}}
\newcommand{\subtitleB}{\fontSubtitle{away from Dangers (s)he cannot perceive.}}
% Titre du diplôme
\newcommand{\diplomaA}{\fontText{Mémoire présenté en vue de l’obtention du diplôme}} % A laisser en Français
\newcommand{\diplomaB}{\fontText{d'Ingénieur Civil en Informatique à finalité Intelligence Computationnelle}}

% Etudiant
\newcommand{\student}{\textbf{\sffamily \large Anthony Debruyn}}

% Supervision
\newcommand{\promAa}{\fontColor{Directeur}}
\newcommand{\promAb}{\fontText{Professeur Mauro Birattari}}
\newcommand{\promBa}{\fontColor{Co-Promoteur}}
\newcommand{\promBb}{\fontText{Professeur Marco Dorigo}}
\newcommand{\promCa}{\fontColor{Superviseur}}
\newcommand{\promCb}{\fontText{Gaëtan Podevijn, AndreaGiovanni Reina}}
\newcommand{\deptA}{\fontColor{Service}}
\newcommand{\deptB}{\fontText{IRIDIA}}

% Année académique
\newcommand{\yearA}{\fontColor{Année académique}}
\newcommand{\yearB}{\fontText{2014 - 2015}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MY NEW COMMANDS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\quoto}[2]{
\begin{quotation}
\textit{\enquote{#1} - #2}
\end{quotation}
}

\newcommand{\quot}[1]{\textit{\enquote{#1}}}


\newcommand{\epuck}[3][0] % [angle]{x}{y} avec angle optionel
{
	\draw [very thick, fill=white] (#2,#3) circle [radius=0.5];
	\draw [very thick, rotate around={#1:(#2,#3)}] (#2-0.25,#3-0.433) -- (#2,#3+0.45) -- (#2+0.25,#3-0.433);
}

\newcommand{\epuckred}[3][0] % [angle]{x}{y} avec angle optionel
{
	\draw [very thick, fill=orange] (#2,#3) circle [radius=0.5];
	\draw [very thick, fill=orange, rotate around={#1:(#2,#3)}] (#2-0.25,#3-0.433) -- (#2,#3+0.45) -- (#2+0.25,#3-0.433);
}

\newcommand{\human}[3][0] % [angle]{x}{y}
{
	\draw [very thick, fill=white, rotate around={#1:(#2,#3)}] (#2-1,#3+0.5) ellipse (0.25cm and 0.5cm);
	\draw [very thick, fill=white, rotate around={#1:(#2,#3)}] (#2+1,#3+0.5) ellipse (0.25cm and 0.5cm);
	\draw [very thick, fill=white, rotate around={#1:(#2,#3)}] (#2,#3) ellipse (1.5cm and 0.75cm);
	\draw [thick, rotate around={#1:(#2,#3)}] (#2-0.05,#3+1) -- (#2,#3+1.1) -- (#2+0.05,#3+1);
	\draw [very thick, fill=white, rotate around={#1:(#2,#3)}] (#2,#3+0.5) circle [radius=0.5cm];
}


\let\oldCaption\caption
\renewcommand{\caption}[2]{
\oldCaption[#1]{{\small\sffamily\bfseries #1:} #2}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NEW STYLES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\captiondelim{ -- }
\captionnamefont{\small\sffamily\bfseries}
\captiontitlefont{\small\sffamily}
\precaption{\rule{\linewidth}{0.4pt}\\}
%\setcounter{secnumdepth}{3}
%\setcounter{tocdepth}{3}
\maxsecnumdepth{subsubsection}% 'secnumdepth' is reset by \mainmatter. You should use 'maxsecnumdepth'.
\maxtocdepth{subsubsection}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THE DOCUMENT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\frontmatter

	\thispagestyle{empty}
	\newgeometry{top=2.5cm, bottom=1.5cm, left=2.5cm, right=1cm}
	\setlength{\unitlength}{1mm}
	\noindent\begin{picture}(175,257)
	
		\put(0,245){\polytech}
		\put(153,139.5){\ulb}
		
		\put(8,155){\makebox(150,10)[l]{\titleA}}
%		\put(8,145){\makebox(150,10)[l]{\titleB}}
		\put(8,135){\makebox(150,10)[l]{\subtitleA}}
		\put(8,125){\makebox(150,10)[l]{\subtitleB}}
		
		\put(0,75){
		\begin{tikzpicture}[scale=0.1]
		\fill [fill=ULBblue](0,0) rectangle (0.8,90);
		\fill [fill=ULBblue](0,47) rectangle (152,47.8);
		\end{tikzpicture}}
		
		\put(8,110){\makebox(150,5)[l]{\diplomaA}}
		\put(8,105){\makebox(150,5)[l]{\diplomaB}}
		
		\put(8,75){\makebox(150,10)[l]{\selectfont \student}}
		
		\put(8,44){\makebox(80,5)[l]{\promAa}}
		\put(8,39){\makebox(80,5)[l]{\promAb}}
		\put(8,31){\makebox(80,5)[l]{\promBa}} % Commenter la ligne si pas nécessaire
		\put(8,26){\makebox(80,5)[l]{\promBb}} % Commenter la ligne si pas nécessaire
		\put(8,18){\makebox(80,5)[l]{\promCa}} % Commenter la ligne si pas nécessaire
		\put(8,13){\makebox(80,5)[l]{\promCb}} % Commenter la ligne si pas nécessaire
		\put(8,5){\makebox(80,5)[l]{\deptA}}
		\put(8,0){\makebox(80,5)[l]{\deptB}}
		
		\put(145,5){\makebox(30,5)[r]{\yearA}}
		\put(145,0){\makebox(30,5)[r]{\yearB}}
	
	\end{picture}
	\restoregeometry
	
% Template conçu par Benjamin Vanhemelryck et revu par François Bronchart - Mai 2013
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BEFORE TEXT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Acknowledgements}

\begin{figure}
	\centering\begin{tikzpicture}
	%Mauro, Gaëtan, Giovanni, Anthony, Lorenzo, Brian, Family and friends.
	\epuck{-5}{12}
	\epuck{-5}{10}
	\epuck{-5}{8}
	\epuck{-5}{6}
	\epuck{-5}{4}
	\epuck{-5}{2}
	\epuck{-5}{0}
	\epuck[60]{-2.5}{-4.33}
	\epuck[120]{2.5}{-4.33}
	\epuck[180]{5}{0}
	
	\draw (-4,12) node[anchor=west] {Mauro Birattari};
	\draw (-4,10) node[anchor=west] {Gaëtan Podevijn};
	\draw (-4,8) node[anchor=west] {Andreagiovanni Reina};
	\draw (-4,6) node[anchor=west] {Anthony Antoun};
	\draw (-4,4) node[anchor=west] {Brian Delhaisse};
	\draw (-4,2) node[anchor=west] {Lorenzo Garattoni};
	\draw (-4,0) node[anchor=west] {Family \& Friends};
	
	\end{tikzpicture}
\end{figure}

\chapter{Résumé}
\chapter{Summary}
\tableofcontents
\listoffigures
\listoftables

\listoftodos

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TEXT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mainmatter
\chapter{Introduction}

[I'll do this and this... blah blah blah...]

\begin{comment}
INTRO
Il faut respecter un fil conducteur dans la thèse. D'abord teaser le contenu dans l'introduction : "j'ai fait un super controller qui peut permettre à des robots de protéger un humain. Ca n'avait jamais été fait avant. J'utilise une swarm. J'ai de très bons résultats. On a testé avec des vrais robots, et l'humain est empêché d'accéder à des zones dangereuses.

STATE OF THE ART
Voici ce qui existe dans le domaine human - robot interaction. Rien de tout cela ne me satisfait et répond à mon problème.

Idem pour human - swarm interaction.

Je vais donc essayer de répondre au problème avec une nouvelle solution... Elle est meilleure que les autres pour ce problème car...

SOLUTION
Pour parvenir à mes fins, j'ai dû implémenter un controller. J'ai choisi virtual physics car ces avantages et inconvénients. C'est ce gars qui l'a inventé, et voici les travaux utilisant cette technique.

\end{comment}

As swarm robotic systems are mostly destined to operate on risky floors, unknown environment, it would seem logical to consider their application in exploration and/or protection missions. However, at the time of writing this thesis, we could not find any study on the subject. Exploration experiments never included a human, or other living organism. The object of this thesis is to address this lack of study by designing and implementing a protective behaviour executed by a robotic swarm.
	
	The human operator is here part of the swarm system. The swarm has to protect him by preventing him from going into dangerous areas, in the same way a group of bodyguards protects someone. The swarm has to follow the operator anywhere to ensure permanent protection.\\
	
	We believe this work to be important since it could lay the foundations of a new branch in swarm engineering: human protection, escort or swarm turn-by-turn navigation.
	
	An article will be written to expose this research to the rest of the swarm robotics community.

\chapter{State of the Art}
	
	In this section, we will discuss the problem that led to the creation of this thesis by first providing the reader with some general insight in the world of swarm robotics and swarm intelligence. Then we will focus on specific parts of these domains of study: feedbacks between human and single robot, and human and robots' swarm.
	
	\section{Human - Robot Interaction}
	
	[Work related to what I do (detect humans, protection, follow person). Conclude on why it cannot be applied to my problem.]

	\section{Swarm Robotics}
	
	[Flocking with a guide, and then Pattern Formation with a Guide. Work related to what I do. Conclude on why it cannot be applied to my problem. Make connections with this part later in the document. S'inspirer de Brambilla pour les flock et pattern.]
	
	This section and the next one are largely inspired by~\citet{brambilla2013swarm}, a reviewing article on swarm engineering. For \citet{csahin2005swarm}, swarm robotics is defined as \quot{the study of how large numbers of relatively simple physically embodied agents can be designed such that a desired collective behavior emerges from the local interactions among agents and between the agents and the environment}~\citep{csahin2005swarm}. Swarm robotics can be separated from other robotic studies by the following characteristics \citep{brambilla2013swarm}:
	
\begin{itemize}
\item Robots are \emph{autonomous}
\item Robots evolve \emph{in the environment} and can interact with it
\item Robots' interactions are \emph{local} (sensors and communications)
\item No \emph{centralised control} or \emph{global knowledge}
\item Robots \emph{cooperate} to achieve a certain goal
\end{itemize}

As in this field of study, one is always looking for \emph{robust}, \emph{scalable} and \emph{flexible} systems, the main source of inspiration is the group of social animals: ants, birds, fishes, ... When some of these simple animals gather in groups, they are able to perform tasks that could not be achieved individually (collective behaviour emerges from local interactions). Below are listed the definitions of these three terms \citep{brambilla2013swarm}:

\label{def:robustness_scalability_flexibility}
\begin{description}
\item[Robustness:] Resistance against \emph{loss of group entities}. One can increase it by adding redundancy or remove the need for a leader.
\item[Scalability:] Low variation in the performance of a system with respect to the \emph{size of the system}. It can be increased by encouraging local interactions, such as sensing and communications.
\item[Flexibility:] Low variation in the performance of a system with respect to the \emph{type of environment or the task}.
\end{description}

With these definitions in mind, we can explain swarm engineering as:

\quoto{Swarm engineering is an emerging discipline that aims at defining systematic and well founded procedures for modeling, designing, realizing, verifying, validating, operating, and maintaining a swarm robotics system.}{\cite{brambilla2013swarm}}

\citet{kazadi2000swarm} points out that \quot{to the swarm engineer, the important points in the design of a swarm are that the swarm will do precisely what it is designed to do, and that it will do so reliably and on time} \citep{kazadi2000swarm}.
	
	\subsection{Human - Robots Swarm Interaction}
	
	[Work related to what I do (detect humans, protection, follow person). Conclude on why it cannot be applied to my problem.]
	
	Human - Robotic swarm interaction is the study of how humans can interact with a swarm to control it and receive feedback from it \citep{brambilla2013swarm}. A proper feedback is needed by the operator in order to make the right decisions. Since swarms must ideally be autonomous and make decisions in a distributed way, it is difficult to insert a communication with a human operator in the system to gain control.\\
	
	Currently, little attention has been devoted to the study of the interaction between humans and robotic swarms, how one can send instructions and receive feedback. People investigating in the field encounter many difficulties, such as the difference of perspective between the swarm and the human operator (the human only observes the global collective behaviour, not the local interactions or individual behaviours driving the robots), the simplicity of the hardware found on the robots, or the efficient synthesis of all the information sent by the robots. All the existing types of interactions in the literature present a major disadvantage: they require an extra layer between the group of robots and the human. This requirement might not always be satisfied when we remember that swarms like this are mostly destined to evolve in an unknown environment. The monitoring equipment necessary to operate the swarm may not be safely deployed. Furthermore, a synthesis of all the local information pieces must be done in order to provide an understandable state of the system to the human. A supplementary step that involves modelling, additional overheads and perhaps heavy computations, and the gathering of all information at a central point (eliminating by the way the distributed and not centralised properties of the swarm system) \citep{podevijn2012self}.\\
	
	\citet{daily2003world} used a head-mounted display and augmented reality to add information right on top of the robot in the environment itself, suppressing the need for an additional display. \citet{baizid2009human} proposed a platform to interact with multiple robots simultaneously through a graphical user interface, or a head-mounted display, virtual reality etc. They also studied how virtual reality abstraction affected the human perception and cognitive capabilities, i.e, they created a virtual environment by filtering useless information. \citet{mclurkin2006speaking} developed an centralised graphical user interface taking inspiration from real-time strategy video games, where one must control armies. They also imagined a feedback approach based on LEDs and sounds. The robots transmit their internal state by applying to their LEDs and sound system a defined pattern, recognisable by the operator, now able to quickly understand the state of the swarm without looking at a supplementary interface.
	
	\citet{podevijn2012self} argue that self-organised mechanism, as those ruling the behaviour of the swarm, should be used to provide feedback to the operator. They suggest that the best entity which could communicate the status of the system and the whole swarm is the swarm itself. They performed experiments using colour feedback to distinguish different internal states and split the swarms into groups to tackle different tasks.\\
	
\begin{comment}
[Currently, only little research on feedback between human and robots swarms. That research is focused on interaction with an additional layer... Mostly unidirectional communication (human to robots). Need new types of interactions for new applications. Robots to human (guide). Write about article saying self-organised feedback is better.] \todo{Remove}
\end{comment}

	
		
		
	
	As swarm robotic systems are mostly destined to operate on risky floors, unknown environment, it would seem logical to consider their application in exploration and/or protection missions. However, at the time of writing this thesis, we could not find any study on the subject. Exploration experiments never included a human, or other living organism. The object of this thesis is to address this lack of study by designing and implementing a protective behaviour executed by a robotic swarm.
	
	The human operator is here part of the swarm system. The swarm has to protect him by preventing him from going into dangerous areas, in the same way a group of bodyguards protects someone. The swarm has to follow the operator anywhere to ensure permanent protection.\\
	
	We believe this work to be important since it could lay the foundations of a new branch in swarm engineering: human protection, escort or swarm turn-by-turn navigation.

%////////////////////////////////////////////////////////////
\chapter{An Escorting Swarm}
%////////////////////////////////////////////////////////////
\label{chap:escorting_swarm}

\begin{comment}
[\textcolor{red}{This is the core of the thesis. It must be a standalone. The reader must understand my work through the reading of this part only!} Explain the solution independently of the tools used to implement the solution. Make the reader understand that this problem is new.

On veut protéger un humain qui ne voit rien comme danger. Solution: un swarm de robots perçu par l'humain avec UN WEARABLE DEVICE (en parler après avoir mentionné le challenge correspondant).

Challenges: une fois qu'on connait la solution générale, parler des challenges, genre comment reconnaître un humain?]\\
\end{comment}

In this chapter, we will explore the investigated problem and the proposed solution at a high level of description. In the next chapter, we will describe the implementation details.

	\section{The Problem}
	
	\begin{comment}
	[Human walking in unknown environment. Team to assist, perceive danger that the human cannot. Graphical example, human goes from A to B with dangers (keep it simple as demo). Write text about an image showing the problem. Mined field, real applications.]\\
	\end{comment}
	
	Since the early days, human beings have explored new territories to expand their control and get a better understanding of the world surrounding them. Among those new landscapes, some were relatively safe but some were dangerous. To overcome this, we have invented equipment, suits, and other kinds of protections. We tried, with this work, to contribute to the study of these solutions.\\
	
	Figure \ref{fig:unknown_environment} shows a graphical representation of a possible scenario. The dangerous areas are the red circles. Those areas could be radioactive areas, mine fields, or any other invisible threats. The human must travel from point \emph{A} to \emph{B} without being hurt by the danger contained in these areas. The human cannot perceive them. The protection created should prevent the user from going inside those areas.\\
	
	Exploration is not the only real application for the proposed solution that comes into mind. Rescue in disaster areas would also benefit from it (evacuation of people to safe zones, etc). The solution should be able to constantly protect the person using it, and constantly provide feedback. It should be robust and fit to the destination environment.
	
%	\begin{figure}\centering
%		\begin{tikzpicture}
%			\draw [dashed] (0,0) circle [radius=1];
%			\draw (0,0) node[scale=2]{A};
%			
%			\draw [dashed] (10,10) circle [radius=1];
%			\draw (10,10) node[scale=2]{B};
%			
%			\draw [dashed, fill=red] (5,5) circle [radius=3];
%			\draw (5,5) node[scale=5]{!};
%			
%			\draw [->, very thick, green] (0,1.5) to [out=90,in=180] (8.5,10);
%			\draw [->, very thick, green] (1.5,0) to [out=0,in=270] (10,8.5);
%			\draw [->, very thick, red] (1.5, 1.5) -- (2.5,2.5);
%		\end{tikzpicture}
%	\end{figure}
	
	\begin{figure}\centering
		\begin{tikzpicture}
			\draw [dashed] (0,0) circle [radius=0.5];
			\draw (0,0) node[scale=2]{A};
			
			\draw [dashed] (12,8) circle [radius=0.5];
			\draw (12,8) node[scale=2]{B};
			
			\draw [dashed, fill=red] (3,0) circle [radius=1.2];
			\draw (3,0) node[scale=5]{!};
			
			\draw [dashed, fill=red] (4.5,3) circle [radius=1.5];
			\draw (4.5,3) node[scale=5]{!};
			
			\draw [dashed, fill=red] (6,7) circle [radius=1];
			\draw (6,7) node[scale=5]{!};
			
			\draw [dashed, fill=red] (10,6) circle [radius=1];
			\draw (10,6) node[scale=5]{!};
			
			\draw [->,very thick, orange] (0.75,0) to [out=0,in=180] (1.5,0) to [out=90,in=200] (3,2) to [out=120,in=-150] (5,6) to [out=-25, in=-160] (8.75,5.5) to [out=110, in=180] (11.25,8);
			
			\draw [very thick] (1,0.433) arc [radius=0.5, start angle=120, end angle=180];
			\draw [very thick] (1,0.433) arc [radius=0.5, start angle=60, end angle=0];
			\draw [very thick] (1,0.433) -- (1,0.933);
			\draw [very thick, fill=white] (1,0.433+0.625) circle [radius=0.125];
			\draw [very thick] (1,0.433+0.375) arc [radius=0.5, start angle=60, end angle=0];
			\draw [very thick] (1,0.433+0.375) arc [radius=0.5, start angle=120, end angle=180];
		\end{tikzpicture}
		
		\caption{Unknown Dangerous Environment}{This image illustrates an environment, observed from above, in which a human must move from point \emph{A} to point \emph{B} while avoiding invisible dangerous areas. \emph{A} is the start location, \emph{B} is the goal ant the red circles represent dangerous zones. We provide in this thesis a solution to guarantee safeness in such circumstances. Possible applications for this type of solutions are: mine fields crossing and cleaning, radioactive areas avoidance,...}
		\label{fig:unknown_environment}
	\end{figure}
	
	
	\section{Solution}
	
	\begin{comment}
	[Solution at high level and the problems I will have to solve? Faire le lien avec flocking et pattern. \textcolor{red}{The swarm is extending the perception capabilities of the human.} Challenges.
	On a choisit d'utiliser des swarms car... Equidistance par rapport à l'humain. Carac du système. Pb pour détecter l'humain...avec solution. Agent de la swarm doit être capable de détecter le danger. Humain perçoit la swarm qui elle perçoit le danger.]
	\end{comment}
	
	The solution we propose involves the use of a swarm of robots. Swarm robotics seems fit to this kind of application, since it is compatible with unknown environments thanks to its flexible, robust and scalable characteristics \citep{brambilla2013swarm}. In case of failure of one or a few robots, the system would continue to provide sufficient performance thanks to its scalability and robustness.\\
	
	The swarm of robots forms a round shield around a user. The round shield formed by the swarm enables a 360° protection of the user. All the robots try to stay at the same distance from each other and the human (except when there is a danger). To achieve this, the final solution relies on the pattern formation theory widely used in swarm robotics\todo{Parler du flocking et pattern.}. The corresponding techniques will be explained in the next chapter with more details. If the number of robots is not high enough to form a complete circle, an arc is formed at the front to always shield the most critical zone.\\
	
	As shown on figure \ref{fig:swarm_preventing}, the robots in contact with a dangerous zone will report the danger through visual communication with the human. Here the robots light on their orange LEDs and stay on the boundary of the zone to prevent the human from getting into it. Since the human cannot see the danger, and only the robots can, we can see that the swarm is increasing the perception capabilities of the human.\\
		
	\begin{figure}\centering
		\begin{tikzpicture}
		
		%	\foreach \i in {\xMin,...,\xMax} {
		%        \draw [very thin,gray] (\i,\yMin) -- (\i,\yMax)  node [below] at (\i,\yMin) {$\i$};
		%    }
		%    \foreach \i in {\yMin,...,\yMax} {
		%        \draw [very thin,gray] (\xMin,\i) -- (\xMax,\i) node [left] at (\xMin,\i) {$\i$};
		%    }
			
			\draw [very thick, dashed, fill=red] (2,6) arc [radius=6, start angle=180, end angle=270];
			
			\human{1}{0}
			
			\draw [dashed] (1,0) circle [radius=4];
			
			\epuckred{2.5}{3.5}
			\epuckred{3.5}{2}
			\epuckred{4.9}{0.8}
			\epuck{4.9}{-1}
			\epuck{4}{-2.5}
			\epuck{2.5}{-3.6}
			\epuck{-2.9}{-1}
			\epuck{-2}{-2.5}
			\epuck{-0.5}{-3.6}
			\epuck{-2.9}{1}
			\epuck{-2}{2.5}
			\epuck{-0.5}{3.6}
					
		\end{tikzpicture}
		
		\caption{Swarm Prevention}{This figure is a symbolic representation of a human helped by a swarm. The circles with a triangle inside are representations of a robot. The swarm tells the human that a dangerous zone is located at the front right by visual communication (here the robots change their colour to red). The swarm stays at the boundary to form a \enquote{shield}. The direction taken by each individual in the swarm is given by the triangle inside (here heading north).}
		\label{fig:swarm_preventing}
	\end{figure}
	
	One issue that had to be resolved was the detection of the human by the robots. As \citet{podevijn2012self} suggested, the interface between the human and the robots swarm should be restricted to the strict minimum because in the field the infrastructure needed to operate the swarm might not be easy to build and manipulate. The swarm should handle the communication on its own. Furthermore, any centralised control system would break the distributed and robust feature of swarm robotics. As a big infrastructure such as a tracking system, or any interface of the same kind would have been difficult to use in real life applications, we designed and implemented a compact, wearable device that allows a human to be recognised by the robots: a pair of shoes.\\
	
	Figure \ref{fig:shoes} illustrates the use of the shoes (no user is wearing them to not occlude the field of view). In figure \ref{fig:shoes} (left), the robots have just recognised the shoes thanks to the LED system inside and begin to move in order to form a circle around the shoe. n figure \ref{fig:shoes} (right), we show an example of one configuration obtained after 3 minutes, viewed from above.\\
	
	\begin{figure}
		\begin{minipage}[c]{0.6\textwidth}
			\includegraphics[trim=200px 300px 140px 300px, clip=true, height=5cm]{images/shoes.jpg}
		\end{minipage}
		\hfill
		\begin{minipage}[c]{0.39\textwidth}
			\hfill\includegraphics[trim=380px 230px 380px 360px, clip=true, height=5cm]{../Experiments/No_Human/6end.png}
		\end{minipage}				
		
		\caption{The Shoes}{This picture shows a prototype of the shoes viewed from above, and the robots interacting with it. The interaction is realised through the recognition of the colours, one for each shoe, indicating left or right side. This pair of shoes enables the robots to locate the user, allowing them to evolve at the target distance from him/her. On the left image, the robots are still in the process of placing themselves in a correct circle. The right image depicts the situation after a 3 minutes experiment where the robots were initially placed in lines around the shoes. Objects are put on the shoes to close the lights switch (normally activated by the weight of the user).}
		\label{fig:shoes}
	\end{figure}

Our objective in this thesis, is to present an innovative protection using swarm robotics. The results obtained with real robots are presented in the chapter \ref{chap:experiments}.

%////////////////////////////////////////////////////////////
\chapter{Implementation}
%////////////////////////////////////////////////////////////

	This chapter details the solution to the given problem and all the choices that resulted in it. The explanation will take a top-down approach, first reviewing the hardware and the general code architecture. It will then go deeper in the details.\\
	
	The first question one could ask is: why swarm robotics for such an application? The answer to that question lays in section \ref{def:robustness_scalability_flexibility}. Robustness, scalability and flexibility are characteristics that make swarms of robots really interesting in unknown environments \citep{brambilla2013swarm}.\todo{Insert more justification?} In case one of the agents is broken, we do not want to see the whole system collapse and leave the human unattended. Flexibility guarantees that the solution will work in different conditions, environments, which is an advantage for exploration and rescue. In case of loss of robots, scalability would maintain the protection performance to an acceptable level.
	
	\section{The Hardware}
	
	The following sections will go through the details of the robots we used to conduct our experiments, and the prototype enabling swarm control.
	
		\subsection{E-puck}
		\label{sec:e-puck}
		
		The robotic platform chosen was the e-puck \citep{mondada2009puck}. This robot model was made for educational purposes, at university level. Its shape is cylindrical with a diameter of 7.5 cm. It is moved by two diametrically opposed wheels. The figure \todo{Insert picture} shows an e-puck from the laboratory. Several extensions were plugged onto it to increase its capabilities. The important sensors that were utilised are the proximity sensors, the omnidirectional camera sensor and the virtual ground sensor. The proximity sensors are based on 8 infrared emitting pieces that return a value proportional to the proximity of an nearby obstacle. These pieces are almost regularly placed a along the perimeter of the robot. The omnidirectional camera is a vertical camera on top of the apparatus, aiming at a convex mirror to provide a 360° view of the environment. The last sensor is a bit special: it is not real, and not physically present on the board. It is simulated through the ARGoS simulator used to develop the controller of the robot. It returns data created inside the simulator to the robot, computed from the simulated environment. In our case, this \enquote{simulated/false data} contains the colour of the ground, symbolising the presence of danger. We actually simulated red discs on the floor through the simulator to artificially set up dangerous areas that were not visible by the testing user. That way, the conditions of real life application were the closest possible to ours. An example of red zone is in figure \ref{fig:e-puck_red_zones}.
		
		\begin{figure}[!h]
			\begin{minipage}[c]{0.49\textwidth}
				\includegraphics[width=\textwidth]{../Experiments/No_Human/red_circle.png}			
			\end{minipage}
			
			\caption{The E-puck and its Virtual Sensor}{}
			\label{fig:e-puck_red_zones}
		\end{figure}
		
		\subsection{E-geta} % Longer text than for e-puck because more important!
		\begin{comment}
		[I will in this section describe the need for a device to detect a human and its development. What are the objectives of the hardware? The choices we made to get the final solution. How we built it. Calibration an adaptation process to make the current algorithm compatible with the new hardware. Where does the term come from?]
		\end{comment}
		
	As explained in chapter \ref{chap:escorting_swarm}, one of the main issue was to enhance the robots so they could detect the user and position themselves with respect to him without any large external equipment. Large external equipments are not recommended since, in the targeted unknown environment, they might not be usable. For example, one might use a tracking system to get the position of the robots in real time and communicate it to the robots for them to adjust their speed. In controlled environment, this may work very well, but in the field it would be difficult to access that knowledge.\\
	
	We thus opted for a compact, wearable device that would act as a \enquote{landmark} for the robots: a pair of shoes. In order for the robots to understand on which side of the human they were (to go in front of the user), the two shoes had to emit a different message. The first idea the team had was to make use of the range and bearing sensors of the e-pucks to interact with the shoes. The shoes would have been equipped with infrared emitters. Unfortunately, tests with real robots demonstrated the inability of the range and bearing sensors to evaluate their distance to the human with precision. This method was abandoned for another one, more reliable: LEDs.\\
	
	The omnidirectional camera sensor, explained in section \ref{sec:e-puck}, provided more accurate data. After validation of this method by tests on the real robots, the decision was made to create a prototype of a pair of shoes equipped with colour lights. Both shoes had to emit a different colour to give the robot information on the direction of the human. In section \ref{sec:robot_behaviour} we come back on the algorithm used to deduce the direction of the human from the observed colours.\\
	
	\begin{comment}
	[Inspiration des getas. Plan ou modèle 3D. Méthode de construction (laser cut pour les plexi etc). Circuit électronique.]
	\end{comment}
	
	\begin{figure}
		\begin{minipage}[c]{0.49\textwidth}
			\includegraphics[width=\textwidth]{images/512px-Geta.jpg}
		\end{minipage}
		\hfill
		\begin{minipage}[c]{0.49\textwidth}
			Insert nice photo of our shoes
		\end{minipage}
		
		\caption{E-Geta}{Left image by Haragayato [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC-BY-SA-3.0 (http://creativecommons.org/licenses/by-sa/3.0/)], via Wikimedia Commons. Found on \citet{wiki:001}.}
		\label{fig:e-geta}
	\end{figure}
	
	The laboratory took inspiration from the Japanese \enquote{geta} shoes for the design. Figure \ref{fig:e-geta} shows a picture of a Japanese wooden shoe called geta. The right side of the figure is a picture of our prototype\todo{Nice picture of shoes}. Both have the same overall design. We chose this design in order to slow down the human's speed. Indeed, he speed of the robots is limited to maximum 10 cm/s for per wheel. Another advantage is the simplicity of the structure, and the low number of assembly parts. Figure \ref{fig:e-geta_blueprints} details the blueprints of the prototype.\todo{Insert blueprints}
	
	\begin{figure}
		Insert blueprints
		
		\caption{E-Geta Blueprints}{Insert text}
		\label{fig:e-geta_blueprints}
	\end{figure}
	
	The base of the shoe is made with wood. The surrounding piece covering the LEDs was cut in sheets of semi-opaque plexiglass to diffuse the light. The LEDs are standard strip LEDs (one red strip, and one green). The final electronic circuit is very simple. The 9 volts battery is connected to two variable voltage regulators (step up) in parallel to increase the potential on the output. Each regulator is connected to a shoe LED strip. A separation is necessary since the green LED strip requires more energy than the red one. To get an equivalent luminosity for both shoes, a different voltage had to be applied.
	
	\begin{figure}\centering
		\includegraphics[scale=0.5]{figures/circuit.png}
		\caption{The Circuit}{The figure shows a sketch of the final electronic circuit for the shoes. The battery delivers 9 volts to two regulators in parallel, one for each shoe since each one of them need a different energy supply. Indeed, the green LED strip is more power hungry than the red one. The mass (black cable) is common for all the circuit.}
	\end{figure}
	
	\section{The Robot Behaviour}
	\label{sec:robot_behaviour}
	
	\begin{comment}
		Pour parvenir à mes fins, j'ai dû implémenter un controller. J'ai choisi virtual physics car ces avantages et inconvénients. C'est ce gars qui l'a inventé, et voici les travaux utilisant cette technique.
		0) Aspect solution avec cercle.
		1) Dois faire un controller en c++, pour la plateforme ARGoS, mais aussi compatible e-puck.
		2) Design de la state machine.
		3) Les potentiels pour chaque state, l'idée de l'algorithme derrière, et leur évolution.
		4) Les paramètres les plus importants ?
	\end{comment}
	
	The first step of the design of the solution is to imagine how the system will look like and how we will implement it, the overall behaviour of the swarm. How do the robots move around the human? What shape will they try to form? This part is important because it will define the overall look and performance of the system.\\
	
	The first shape that intuitively comes in mind is the circle. The circle is the most elementary shape in geometry. It offers the best ratio:
	$$\frac{\mbox{\textit{Surface}}}{\mbox{\textit{Perimeter}}} = \frac{\pi r^2}{2\pi r} = \frac{r}{2}~\mbox{, where r is the radius of the circle.}$$
	
	That means that fewer robots are needed for the same protected area, and more space for the human with a certain amount of robots than any other possible shape. Luckily, it is also the easiest shape to realise in practice. The figure \ref{fig:circle_shape} represents the kind of circle that we would like to obtain for 6 robots and 1 human in the centre. All the robots are equally distanced from each other and the human. The human is protected in all directions. In presence of danger, the robots in contact with it should report it to the human and prevent him from going towards it, as seen on figure \ref{fig:swarm_preventing}. In that case, the conditions concerning the target distance from the human and between robot may not be respected.\\
	
	\begin{figure}[!h]\centering
	\begin{tikzpicture}
		\draw [dashed] (0,0) circle [radius=4];
		\epuck{4}{0}
		\epuck{2}{3.464}
		\epuck{-2}{3.464}
		\epuck{-4}{0}
		\epuck{-2}{-3.464}
		\epuck{2}{-3.464}
		
		\human{0}{0}
	\end{tikzpicture}
	\caption{Ideal Behaviour in Absence of Danger}{This figure symbolises the ideal behaviour required in absence of danger. The swarm forms a circle to cover the widest protected surface for a given amount of robots. All the robots are equally distanced from each other and the human. The human is protected in all directions. In presence of danger, the robots in contact with it should report it to the human and prevent him from going towards it, as seen on figure \ref{fig:swarm_preventing}. In that case, the conditions concerning the target distance from the human and between robot may not be respected.}
	\label{fig:circle_shape}
	\end{figure}	
	
	Implementing a robots swarm behaviour means writing a controller code for its individual components: the robots. The laboratory provides a template in the Lua and the C++ languages for this purpose. The logic of the individual behaviour is added inside callback methods called either by the simulator when performing simulations inside ARGoS \citep{pinciroli2012argos}, or by the robot main method when testing on real robots. The first attempts to build the core of the controller were made in Lua to accelerate the process of trial and error. Indeed, Lua has a simpler syntax, is interpreted by the simulator and does not require any compilation process. Furthermore, the debugging is faster since the simulator includes an editor for the lua controller code. Although Lua is very convenient for quick implementation, it is not supported by the robots. Hence a translation was necessary to port the code to C++ in order to begin the tests on the real robots. After that, the implementation continued exclusively in C++ since the tests on the robots were more frequent. The C++ template developed by the laboratory can be compiled for the ARGoS simulator and cross-compiled for the real robots (e-puck) without any modification. After the compilation, a simple transfer of the binary codes over WiFi allows the operator to store the controller on the robots to launch an experiment.\\
	
	The final implementation of the controller is built on 2 layers. The upper layer is a deterministic finite state machine, containing for each state a specific behaviour in the lower layer. Figure \ref{fig:state_machine} illustrates the whole structure of the upper layer. Figure \ref{fig:state_machine} (left) is what could be called the \enquote{core} of the behaviour, while fig. \ref{fig:state_machine} (right) would be considered as additions to enhance the behaviour. The core part of the state machine is present on fig. \ref{fig:state_machine} (right) since it is one of its constituents. One can only limit himself to core part to understand the behaviour. It is composed of 3 states: \emph{R.W. (Random Walking)} when the robots do not detect any human nor obstacle, \emph{Escorting} when a human is detected, and \emph{Protection} when a human is detected and there is a danger nearby. If an obstacle is detected by a robot, the latter escapes from the core behaviour of the state machine and enters the \emph{O.A. (Obstacle Avoidance} state. If the robot is blocked for too long, another state takes over to unblock it: \emph{Unblocking}. When no more obstacle is in front of the robot, it can go back to its obstacle avoidance if any obstacle remains close. If none, it switches back to its core actions. The labels next to each transition must be read as follows: \emph{H(uman)}, \emph{D(anger)}, \emph{O(bstacle)}, \emph{F(ront obstacle)}, \emph{T(hreshold crossed, stuck for too long and initiating rotation procedure to escape from the obstacles)}. \emph{N} stands for the negation, so \emph{NH} means \enquote{no human found}. A complete state machine gathering all the states can be found in \ref{app:complete_state_machine}. Although the complete state machine is containing all the aspects of the behaviour, it does not allow to grasp the idea quickly. Dividing the final behaviour into several connected sub-behaviours modularises the solution. Adding a new state, a new sub-behaviour is easy.\\
	
	\begin{figure}[!h]\centering
		\begin{minipage}[c]{.49\textwidth}
			\begin{tikzpicture}[->, >=stealth', shorten >=1pt, auto, node distance=4cm, semithick]
				\node[initial,state] (RW)                    {R.W.};
		  		\node[state]         (E) [below right of=RW] {Escorting};
		  		\node[state]         (P) [below left of=RW] {Protection};
		  		
		  		\path	(RW)	 edge[bend left] node{\color{gray} H} (E)
		  				(RW)	 edge node{\color{gray} H\&D} (P)
		  				(E) edge node {\color{gray} NH}	(RW)
		  				(E) edge[bend left] node {\color{gray} D}	(P)
		  				(P) edge node {\color{gray} ND}	(E)
		  				(P) edge[bend left] node[yshift=-0.2cm] {\color{gray} NH}	(RW);

			\end{tikzpicture}
			
%			\resizebox{\textwidth}{!}{%
		  				
		\end{minipage}
		\hfill
		\begin{minipage}[c]{.49\textwidth}
		\resizebox{\textwidth}{!}{%
			\begin{tikzpicture}[->, >=stealth', shorten >=1pt, auto, node distance=4cm, semithick]
				\node[initial,state] (C)                    {Core};
		  		\node[state]         (O) [above right of=C] {O.A.};
		  		\node[state]         (U) [above left of=C] {Unblocking};
		  		
		  		\path	(C)	edge[bend right] node[below,xshift=0.1cm]{\color{gray} O} (O)
		  				(O) edge node[above,xshift=-0.2cm] {\color{gray} NO}	(C)
		  				(O) edge[bend right] node {\color{gray} T}	(U)
		  				(U) edge node[below] {\color{gray} NF\&O}	(O)
		  				(U) edge[bend right] node[yshift=-0.2cm] {\color{gray} NF}	(C);

			\end{tikzpicture}}
		\end{minipage}
		
		\caption{State Machine of the Final Behaviour}{This figure is the visual representation of the state machine of the final behaviour. Figure \ref{fig:state_machine} (left) is what could be called the \enquote{core} of the behaviour, while fig. \ref{fig:state_machine} (right) would be considered as additions to enhance the behaviour. The core part of the state machine is present on fig. \ref{fig:state_machine} (right) since it is one of its constituents. The abbreviations R.W. and O.A. respectively mean \enquote{random walking} and \enquote{obstacle avoidance}. The labels next to each transition must be read as follows: H(uman), D(anger), O(bstacle), F(ront obstacle), T(hreshold crossed, stuck for too long and initiating rotation procedure to escape from the obstacles). N stands for the negation, so NH means \enquote{no human found}.}
		\label{fig:state_machine}
	\end{figure}

	Once the actions the robots have to execute have been defined, we have to implement them, code them in the controller that will be run. So the next step was to find a way to translate those actions into code. Our behaviour is a kind of coordinated motion and pattern formation. Thus the intuitive way of implementing it was to make use of the virtual physics design. Using this framework, each robot is a particle subject to virtual forces exerted by the environment (the other robots, the obstacles, and other elements). \citet{khatib1986real} was among the first to use this method. His goal was to implement an obstacle avoidance swarm behaviour where the obstacles create repulsive forces and the goals attractive forces. The overall resulting potential presented local minima at goals and maxima at obstacles. \citet{reif1999social} introduces \enquote{social potential fields} consisting in virtual forces applied on robots by other robots, obstacles, objectives,... The robot resultant motion is defined by the sum of all the forces applied to it. The individual robots carry out the calculations themselves, so the final control is completely distributed. The laws they used are similar to those found in molecular dynamics (inverse-power laws). For example, a law could favour attraction over long distances and repulsion over short distances. One of these is the Lennard-Jones potential, depicted in figure \ref{fig:lennard-jones_potential}. Inverse-power laws, while being extremely simple, can form interesting and elaborate patterns with molecules and plasma gases \citep{reif1999social}. \citet{spears2004distributed} proposed a framework they call \enquote{physicomimetics} to grant distributed control over a large swarm of robots with \enquote{artificial physics}.\\
	
	\begin{figure}
	\begin{minipage}[c]{0.6\textwidth}
		\begin{tikzpicture}
			\begin{axis}[
			    samples=100,
			    domain=0:1, xmax=1,
			    restrict y to domain=-4:10,
			    axis lines=left,
			    y=1cm/2,
			    x=10cm,
			    grid=both,
			    xtick={0,0.1,...,1},
			    ytick={-4,-2,...,10},
			    compat=newest,
			    xlabel=$d$, xlabel style={at={(1,0)}, anchor=west},
			    ylabel=$f$, ylabel style={rotate=-90,at={(0,1)}, anchor=south}
			]
			\addplot [red, thick] {2.5*((0.3/x)^12 - 2*(0.3/x)^6)};
			\end{axis}
		\end{tikzpicture}
	\end{minipage}
	\hfill
	\begin{minipage}[c]{0.4\textwidth}
		$$ y = f(d) = \epsilon \left[ \left(\frac{\sigma}{d}\right)^{12} - 2 \left(\frac{\sigma}{d}\right)^6 \right]$$
		$$\epsilon = 2.5$$
		$$\sigma = 0.3$$
	\end{minipage}
		
		\caption{The Lennard-Jones Potential}{This figure shows a graph of one of the most used virtual potentials in virtual physics, the Lennard-Jones potential, where $\epsilon$ is the gain, $\sigma$ is the target distance and $d$ is the current real distance.}
		\label{fig:lennard-jones_potential}
	\end{figure}
	
	Using virtual physics offers some advantages over the other methods \citep{brambilla2013swarm}:
	
	\begin{enumerate}
		\item Only one mathematical formula fluently and elegantly converts all the inputs into outputs for the actuators. It removes the need for multiple rules and behaviours.
		$$f:\mathbb{R}^m \rightarrow \mathbb{R}^n:x_1,x_2,...,x_m \rightarrow y_1,y_2,...,y_n = f(x_1,x_2,...,x_m)\mbox{,}$$ where $m$ is the number of inputs, $n$ is the number of outputs and $f$ is the translating function.
		
		\item Multiple behaviours can be combined by simply summing the corresponding resulting vectors.
		$$y_1,y_2,...,y_n = g(x_1,x_2,...,x_m) = \sum_{i=0}^{s}{f_i(x_1,x_2,...,x_m)}\mbox{,}$$ where $s$ is the number of behaviour components.
	\end{enumerate}
	
	The laws of physics force a system to get to a state of minimum energy, i.e., to reach a global minimum of the potential function of the system. Since the force is proportional to the derivative of the corresponding potential, the minimum of the potential function means the disappearance of the forces. For the forces to disappear, every robot needs to be at the desired location.
	
	$$\vec{f} = -\vec{\nabla}P,$$, P being the system's potential. The following sections will explain in detail the different potentials that were implemented to obtain the desired behaviour.
			
		In this section, the potentials are grouped by states in which they are used. Since virtual physics are used in only 2 states, we have only 2 groups. Only part of the states rely on virtual physics: \emph{Human} and \emph{Default}. The others simply link the sensor values to the wheels speed.
		
			\paragraph{Human}
			
			The controller enters the \emph{Human} state at the beginning of the time step only if a human is found nearby. The complete potential for this state is the sum of 3 components: the \emph{human potential}, the \emph{gravity potential} and the \emph{agent repulsion potential}.
			
			\begin{enumerate}
				
				\item Human Potential
					
					\begin{figure}[!h]\centering
						\begin{tikzpicture}[xscale=0.2,yscale=0.2]
							\draw [<->] (0,5) -- (0,0) -- (70,0);
							\draw[blue,thick, domain=28:70] plot (\x, {-4*500/\x*((30/\x)^4-(30/\x)^2)});
							
							\foreach \x [evaluate=\x as \j using \x*10]in {0,...,6}
							    \draw (\j cm,5pt) -- (\j cm,-5pt) node[anchor=north] {$\j$};
							%\foreach \y in {0,1,2,3,4}
							%    \draw (1pt,\y cm) -- (-1pt,\y cm) node[anchor=east] {$\y$};
						\end{tikzpicture}
					\end{figure}
					
				\item Gravity Potential
				
				[Description of the evolution of the gravity potential.]
				
				\item Agent Repulsion Potential
				
				[Idem for agent repulsion pot.]
			\end{enumerate}
		
			\paragraph{Obstacle}
			
			[Idem for obstacle case.			
						
			\paragraph{Default}
			
			[Idem for the default state and potential.]
			
			\paragraph{Blocked}
			
			[Idem for blocked state.]
		

\chapter{Experiments}
\label{chap:experiments}
[\textcolor{red}{Explain very clearly both types of tests (no human/human.} ]

	\section{Characterisation of the System}
	[The measurements and the tests on the final behaviour.]

		\subsection{Metrics}
		
		[Metrics I will use. Their description. How I will compute them.]
		
			\paragraph{Correct Distance}
			
			[Do the robots respect the correct wanted distance?]
			
			\paragraph{Robot Density}
			
			[Do the robots surround the human correctly?]
			
			\paragraph{Time}
			
			[Do they do that in a relatively low amount of time?]
			
		\subsection{Set-up}
		
		[How I am performing my experiments.]
		
		\subsection{Analysis}
		
		[All the graphs we discussed about. The evolution of the error over time. The analysis of the behaviour on basis of the criteria we defined.]
		
	\section{Demonstration}
	
	[What demonstration was done with the device. Add pictures. Describe perfectly.]

\chapter{Conclusion}

[I've done this, this and this (~1/2 pages). (Intro: "I'll do this, this...) \textcolor{red}{Put sentences of type "so what?". Continuous text.}

	\paragraph{Future Works}
	[The future works that would be interesting from my point of view.]
	
		\subparagraph{Other Robots}
		\subparagraph{Guidance}
			
			\begin{description}
				\item[Zero Visibility Areas or Blind People:]
				\item[Human Motion Synchronisation:]
				\item[Vehicle Guidance:]
			\end{description}
			


\appendix

\chapter{The Complete State Machine}
\label{app:complete_state_machine}

\begin{figure}[!h]\centering
	\begin{minipage}[c]{.49\textwidth}
%			\begin{tikzpicture}[->, >=stealth', shorten >=1pt, auto, node distance=4cm, semithick]
%				\node[initial,state] (NORMAL)                    {Normal};
%		  		\node[state]         (OBS) [below left of=NORMAL] {Obstacle};
%		  		\node[state]         (HU) [below of=NORMAL] {Human};
%		  		\node[state]         (DEF) [below right of=NORMAL] {Default};
%		  		\node[state]         (BLOCK) [above of=NORMAL]       {Blocked};
%		  		
%		  		\path	(BLOCK)		edge		node					{\color{gray} 1}	(NORMAL)
%		  				(NORMAL)		edge		node[yshift=0.2cm]	{\color{gray} 2}	(OBS)
%		  				(NORMAL)		edge		node					{\color{gray} 3}	(HU)
%		  				(NORMAL)		edge		node	[yshift=-0.2cm]	{\color{gray} 4}	(DEF)
%		  				(OBS)		edge		[bend left]	node		{\color{gray} 5}	(BLOCK)
%		  				(OBS)		edge		[bend right]	node		{}				(NORMAL)
%		  				(HU)			edge		[bend right]	node		{}				(NORMAL)
%		  				(DEF)		edge		[bend right]	node		{}				(NORMAL);
%			\end{tikzpicture}
%			
		\resizebox{\textwidth}{!}{%
		\begin{tikzpicture}[->, >=stealth', shorten >=1pt, auto, node distance=4cm, semithick]
	  		\node[state]         (OBS)					{Obstacle Avoidance};
	  		\node[state]         (HU) [below of=OBS]		{Escorting};
	  		\node[state]         (DEF) [below of=HU]		{Random Walk};
	  		\node[state]         (BLOCK) [right of=HU]	{Unblocking};
	  		\node[state]         (DANGER) [left of=HU]	{Protection};
	  		
	  		\path	(OBS)		edge	[bend left]	node		{\color{gray} 1}	(BLOCK)
	  				(OBS)		edge	[bend left]	node[yshift=-1.2cm, xshift=-0.3cm]		{\color{gray} 2}				(DEF)
	  				(OBS)		edge	[bend left]	node	[left]	{\color{gray} 3}				(HU)
	  				(HU)			edge	[bend left]	node[right]		{\color{gray} 4}				(OBS)
	  				(HU)			edge	[bend left]	node	[left]	{\color{gray} 2}				(DEF)
	  				(DEF)		edge	[bend left]	node[right]		{\color{gray} 3}				(HU)
	  				(DEF)		edge	[bend left]	node	[right, yshift=0.2cm]	{\color{gray} 4}				(OBS)
	  				(BLOCK)		edge				node		{\color{gray} 5}				(OBS)
	  				(BLOCK)		edge				node	[xshift=0.3cm]	{\color{gray} 6}				(HU)
	  				(BLOCK)		edge	[bend left]			node		{\color{gray} 7}				(DEF)
	  				(BLOCK)		edge	[bend left, above]	node[yshift=-0.1cm]		{\color{gray} 8}				(DANGER)
	  				(HU)		edge	[bend left, above]	node		{\color{gray} 9}				(DANGER)
	  				(DANGER)	 edge[bend left, above] node{\color{gray} 3} (HU)
	  				(DANGER)	 edge[bend left, above] node{\color{gray} 4} (OBS)
	  				(OBS)	 edge[above] node{\color{gray} 9} (DANGER)
	  				(DANGER)	 edge[below] node{\color{gray} 2} (DEF)
	  				(DEF)	 edge[bend left, below] node{\color{gray} 9} (DANGER);
	  				
		\end{tikzpicture}
		}
	\end{minipage}
	\hfill
	\begin{minipage}[c]{.49\textwidth}
		\small\sffamily
		
		\begin{enumerate}
			\item Amount of direction change (left/right) while having an obstacle around reaches a threshold.
			\item No human \& no obstacle.
			\item No obstacle \& human \& no danger.
			\item Obstacle.
			\item No front obstacle \& obstacle elsewhere.
			\item No front obstacle \& human \& no danger.
			\item No front obstacle \& no human \& no obstacle.
			\item No front obstacle \& human \& danger.
			\item No obstacle \& human \& danger.

			\end{enumerate}

%			\begin{enumerate}
%				\item No more obstacle in front.
%				\item Obstacle found around the robot.
%				\item Human found around the robot.
%				\item Neither of the previous criteria met.
%				\item Amount of direction change (left/right) while having an obstacle around reaches a threshold.
%			\end{enumerate}
	\end{minipage}
	
	\caption{State Machine of the Final Behaviour}{This figure is the visual representation of the state machine of the final behaviour. On the left, the states and their connections are drawn. On the right, the information on the conditions needed to take the transitions are listed.}
	\label{fig:state_machine}
\end{figure}

\chapter{E-puck}

\chapter{ARGoS}

\chapter{Arena Tracking System}

\chapter{Range and Bearing}

\chapter{Omnidirectional Camera}

\chapter{Controller Code}

\chapter{MATLAB Scripts Code}

\chapter{Human Detection Devices Blueprints}

\backmatter
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{filecontents}{thesis.bib}
%http://en.wikibooks.org/wiki/LaTeX/Bibliography_Management

@inproceedings{podevijn2012self,
  title={Self-organised feedback in human swarm interaction},
  author={Podevijn, Ga{\"e}tan and O’Grady, Rehan and Dorigo, Marco},
  booktitle={Proceedings of the workshop on robot feedback in human-robot interaction: how to make a robot readable for a human interaction partner (Ro-Man 2012)},
  year={2012}
}

@incollection{podevijn2014gesturing,
  title={Gesturing at subswarms: Towards direct human control of robot swarms},
  author={Podevijn, Ga{\"e}tan and O’Grady, Rehan and Nashed, Youssef SG and Dorigo, Marco},
  booktitle={Towards Autonomous Robotic Systems},
  pages={390--403},
  year={2014},
  publisher={Springer}
}

@article{brambilla2013swarm,
  title={Swarm robotics: a review from the swarm engineering perspective},
  author={Brambilla, Manuele and Ferrante, Eliseo and Birattari, Mauro and Dorigo, Marco},
  journal={Swarm Intelligence},
  volume={7},
  number={1},
  pages={1--41},
  year={2013},
  publisher={Springer}
}

@incollection{csahin2005swarm,
  title={Swarm robotics: From sources of inspiration to domains of application},
  author={{\c{S}}ahin, Erol},
  booktitle={Swarm robotics},
  pages={10--20},
  year={2005},
  publisher={Springer}
}

@phdthesis{kazadi2000swarm,
  title={Swarm engineering},
  author={Kazadi, Sanza T},
  year={2000},
  school={California Institute of Technology}
}

@book{minsky1967computation,
  title={Computation: finite and infinite machines},
  author={Minsky, Marvin L},
  year={1967},
  publisher={Prentice-Hall, Inc.}
}

@article{granovetter1978threshold,
  title={Threshold models of collective behavior},
  author={Granovetter, Mark},
  journal={American journal of sociology},
  pages={1420--1443},
  year={1978},
  publisher={JSTOR}
}

@inproceedings{bonabeau1997adaptive,
  title={Adaptive Task Allocation Inspired by a Model of Division of Labor in Social Insects.},
  author={Bonabeau, Eric and Sobkowski, Andrej and Theraulaz, Guy and Deneubourg, Jean-Louis},
  booktitle={BCEC},
  pages={36--45},
  year={1997}
}

@article{bachrach2010composable,
  title={Composable continuous-space programs for robotic swarms},
  author={Bachrach, Jonathan and Beal, Jacob and McLurkin, James},
  journal={Neural Computing and Applications},
  volume={19},
  number={6},
  pages={825--847},
  year={2010},
  publisher={Springer}
}

@article{wolpert1999introduction,
  title={An introduction to collective intelligence},
  author={Wolpert, David H and Tumer, Kagan},
  journal={arXiv preprint cs/9908014},
  year={1999}
}

@article{abbott2006emergence,
  title={Emergence explained: Abstractions: Getting epiphenomena to do real work},
  author={Abbott, Russ},
  journal={Complexity},
  volume={12},
  number={1},
  pages={13--26},
  year={2006},
  publisher={Wiley Online Library}
}

@article{pinciroli2012argos,
  title={{ARGoS}: a Modular, Parallel, Multi-Engine Simulator for Multi-Robot Systems},
  author={Carlo Pinciroli and Vito Trianni and Rehan O'Grady and Giovanni Pini and Arne Brutschy and Manuele Brambilla and Nithin Mathews and Eliseo Ferrante and Gianni {Di Caro} and Frederick Ducatelle and Mauro Birattari and Luca Maria Gambardella and Marco Dorigo},
  journal={Swarm intelligence},
  volume={6},
  number={4},
  pages={271--295},
  year={2012},
  publisher={Springer},
  address = {Berlin, Germany}
}

@inproceedings{daily2003world,
  title={World embedded interfaces for human-robot interaction},
  author={Daily, Mike and Cho, Youngkwan and Martin, Kevin and Payton, Dave},
  booktitle={System Sciences, 2003. Proceedings of the 36th Annual Hawaii International Conference on},
  pages={6--pp},
  year={2003},
  organization={IEEE}
}

@incollection{baizid2009human,
  title={Human multi-robots interaction with high virtual reality abstraction level},
  author={Baizid, Khelifa and Li, Zhao and Mollet, Nicolas and Chellali, Ryad},
  booktitle={Intelligent Robotics and Applications},
  pages={23--32},
  year={2009},
  publisher={Springer}
}

@inproceedings{mclurkin2006speaking,
  title={Speaking Swarmish: Human-Robot Interface Design for Large Swarms of Autonomous Mobile Robots.},
  author={McLurkin, James and Smith, Jennifer and Frankel, James and Sotkowitz, David and Blau, David and Schmidt, Brian},
  booktitle={AAAI Spring Symposium: To Boldly Go Where No Human-Robot Team Has Gone Before},
  pages={72--75},
  year={2006}
}

@inproceedings{mondada2009puck,
  title={The e-puck, a robot designed for education in engineering},
  author={Mondada, Francesco and Bonani, Michael and Raemy, Xavier and Pugh, James and Cianci, Christopher and Klaptocz, Adam and Magnenat, Stephane and Zufferey, Jean-Christophe and Floreano, Dario and Martinoli, Alcherio},
  booktitle={Proceedings of the 9th conference on autonomous robot systems and competitions},
  volume={1},
  number={LIS-CONF-2009-004},
  pages={59--65},
  year={2009},
  organization={IPCB: Instituto Polit{\'e}cnico de Castelo Branco}
}

@misc{wiki:001,
   author = "Wikipedia",
   title = "Geta (footwear) --- Wikipedia{,} The Free Encyclopedia",
   year = "2015",
   url = "\url{http://en.wikipedia.org/w/index.php?title=Geta_(footwear)&oldid=651925222}",
   note = "[Online; accessed 20-May-2015]"
 }
 
 @article{khatib1986real,
  title={Real-time obstacle avoidance for manipulators and mobile robots},
  author={Khatib, Oussama},
  journal={The international journal of robotics research},
  volume={5},
  number={1},
  pages={90--98},
  year={1986},
  publisher={Sage Publications}
}

@article{reif1999social,
  title={Social potential fields: A distributed behavioral control for autonomous robots},
  author={Reif, John H and Wang, Hongyan},
  journal={Robotics and Autonomous Systems},
  volume={27},
  number={3},
  pages={171--194},
  year={1999},
  publisher={Elsevier}
}

@article{spears2004distributed,
  title={Distributed, physics-based control of swarms of vehicles},
  author={Spears, William M and Spears, Diana F and Hamann, Jerry C and Heil, Rodney},
  journal={Autonomous Robots},
  volume={17},
  number={2-3},
  pages={137--162},
  year={2004},
  publisher={Springer}
}

\end{filecontents}

%\nocite{*}
\bibliographystyle{plainnat}
\bibliography{thesis}

\end{document}
